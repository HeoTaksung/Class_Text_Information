{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"book\", quiet=True)\n",
    "\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n"
     ]
    }
   ],
   "source": [
    "emma_raw = nltk.corpus.gutenberg.raw(\"austen-emma.txt\")\n",
    "print(emma_raw[:702])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긴 글을 문장 단위로 토큰화\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentence = sent_tokenize(emma_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.', \"She was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.\"]\n"
     ]
    }
   ],
   "source": [
    "print(sentence[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장을 단어 단위로 토큰화\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_token = []\n",
    "\n",
    "for line in sentence:\n",
    "    word_token.append(word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER', 'I', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.'], ['She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(word_token[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "tagged_data = []\n",
    "pos_dict = {}\n",
    "\n",
    "for i in word_token:\n",
    "    tagged = pos_tag(i)\n",
    "    tagged_data.append(tagged)\n",
    "    \n",
    "    for j in tagged:\n",
    "        pos_dict[j] = 0\n",
    "\n",
    "for i in tagged_data:\n",
    "    for j in i:\n",
    "        pos_dict[j] += 1\n",
    "\n",
    "pos_dic = sorted(pos_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('[', 'NNS'), ('Emma', 'NNP'), ('by', 'IN'), ('Jane', 'NNP'), ('Austen', 'NNP'), ('1816', 'CD'), (']', 'NNP'), ('VOLUME', 'NNP'), ('I', 'PRP'), ('CHAPTER', 'VBP'), ('I', 'PRP'), ('Emma', 'NNP'), ('Woodhouse', 'NNP'), (',', ','), ('handsome', 'NN'), (',', ','), ('clever', 'NN'), (',', ','), ('and', 'CC'), ('rich', 'JJ'), (',', ','), ('with', 'IN'), ('a', 'DT'), ('comfortable', 'JJ'), ('home', 'NN'), ('and', 'CC'), ('happy', 'JJ'), ('disposition', 'NN'), (',', ','), ('seemed', 'VBD'), ('to', 'TO'), ('unite', 'VB'), ('some', 'DT'), ('of', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('blessings', 'NNS'), ('of', 'IN'), ('existence', 'NN'), (';', ':'), ('and', 'CC'), ('had', 'VBD'), ('lived', 'VBN'), ('nearly', 'RB'), ('twenty-one', 'CD'), ('years', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('world', 'NN'), ('with', 'IN'), ('very', 'RB'), ('little', 'JJ'), ('to', 'TO'), ('distress', 'VB'), ('or', 'CC'), ('vex', 'VB'), ('her', 'PRP'), ('.', '.')], [('She', 'PRP'), ('was', 'VBD'), ('the', 'DT'), ('youngest', 'JJS'), ('of', 'IN'), ('the', 'DT'), ('two', 'CD'), ('daughters', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('most', 'RBS'), ('affectionate', 'JJ'), (',', ','), ('indulgent', 'JJ'), ('father', 'NN'), (';', ':'), ('and', 'CC'), ('had', 'VBD'), (',', ','), ('in', 'IN'), ('consequence', 'NN'), ('of', 'IN'), ('her', 'PRP$'), ('sister', 'NN'), (\"'s\", 'POS'), ('marriage', 'NN'), (',', ','), ('been', 'VBN'), ('mistress', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('house', 'NN'), ('from', 'IN'), ('a', 'DT'), ('very', 'RB'), ('early', 'JJ'), ('period', 'NN'), ('.', '.')]]\n",
      "\n",
      "POS dictionary :  [(('!', '.'), 1063), (('&', 'CC'), 3), ((\"'\", \"''\"), 103), ((\"'\", 'POS'), 20), ((\"''\", \"''\"), 2452)]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_data[:2], end='\\n\\n')\n",
    "print('POS dictionary : ', pos_dic[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The event had every promise of happiness for her friend.\n",
      "[('The', 'DT'), ('event', 'NN'), ('had', 'VBD'), ('every', 'DT'), ('promise', 'NN'), ('of', 'IN'), ('happiness', 'NN'), ('for', 'IN'), ('her', 'PRP$'), ('friend', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(sentence[13])\n",
    "print(tagged_data[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "promise_list = []\n",
    "\n",
    "for i in range(len(pos_dic)):\n",
    "    if pos_dic[i][0][0] == 'promise':\n",
    "        promise_list.append(pos_dic[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('promise', 'NN'), 7), (('promise', 'VB'), 13), (('promise', 'VBP'), 1)]\n"
     ]
    }
   ],
   "source": [
    "print(promise_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')\n",
    "nltk.help.upenn_tagset('VB')\n",
    "nltk.help.upenn_tagset('VBP')\n",
    "nltk.help.upenn_tagset('DT')\n",
    "nltk.help.upenn_tagset('IN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_dic에 저장되어 있는 list :  (('Taylor', 'NNP'), 47)\n",
      "pos_dic의 튜플 형태 :  ('Taylor', 'NNP')\n",
      "품사 :  NNP\n",
      "품사 개수 :  47\n"
     ]
    }
   ],
   "source": [
    "total_DT = 0    # promise 왼쪽의 품사\n",
    "total_IN = 0    # promise 오른쪽의 품사\n",
    "\n",
    "total_NN = 0    # promise에서 나타나는 품사들\n",
    "total_VB = 0\n",
    "total_VBP = 0\n",
    "\n",
    "for i in range(len(pos_dic)):\n",
    "    if pos_dic[i][0][1] == 'DT':\n",
    "        total_DT += pos_dic[i][1]\n",
    "    elif pos_dic[i][0][1] == 'IN':\n",
    "        total_IN += pos_dic[i][1]\n",
    "    elif pos_dic[i][0][1] == 'NN':\n",
    "        total_NN += pos_dic[i][1]\n",
    "    elif pos_dic[i][0][1] == 'VB':\n",
    "        total_VB += pos_dic[i][1]\n",
    "    elif pos_dic[i][0][1] == 'VBP':\n",
    "        total_VBP += pos_dic[i][1]\n",
    "        \n",
    "print(\"pos_dic에 저장되어 있는 list : \", pos_dic[800])\n",
    "print(\"pos_dic의 튜플 형태 : \", pos_dic[800][0])\n",
    "print(\"품사 : \",pos_dic[800][0][1])\n",
    "print(\"품사 개수 : \", pos_dic[800][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12743\n",
      "17880\n",
      "19330\n",
      "8941\n",
      "3389\n"
     ]
    }
   ],
   "source": [
    "print(total_DT)\n",
    "print(total_IN)\n",
    "print(total_NN)\n",
    "print(total_VB)\n",
    "print(total_VBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_into_NN = 0  # DT에서 NN으로\n",
    "NN_into_IN = 0  # NN에서 IN으로\n",
    "\n",
    "DT_into_VB = 0  # DT에서 VB로\n",
    "VB_into_IN = 0  # VB에서 IN으로\n",
    "\n",
    "DT_into_VBP = 0  # DT에서 VBP로\n",
    "VBP_into_IN = 0  # VBP에서 IN으로\n",
    "\n",
    "for i in range(len(tagged_data)):\n",
    "    for j in range(len(tagged_data[i])-1):\n",
    "        if tagged_data[i][j][1] == 'DT' and tagged_data[i][j+1][1] == 'NN':\n",
    "            DT_into_NN += 1\n",
    "        elif tagged_data[i][j][1] == 'NN' and tagged_data[i][j+1][1] == 'IN':\n",
    "            NN_into_IN += 1\n",
    "        elif tagged_data[i][j][1] == 'DT' and tagged_data[i][j+1][1] == 'VB':\n",
    "            DT_into_VB += 1\n",
    "        elif tagged_data[i][j][1] == 'VB' and tagged_data[i][j+1][1] == 'IN':\n",
    "            VB_into_IN += 1\n",
    "        elif tagged_data[i][j][1] == 'DT' and tagged_data[i][j+1][1] == 'VBP':\n",
    "            DT_into_VBP += 1\n",
    "        elif tagged_data[i][j][1] == 'VBP' and tagged_data[i][j+1][1] == 'IN':\n",
    "            VBP_into_IN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6838\n",
      "5154\n",
      "15\n",
      "1073\n",
      "39\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "print(DT_into_NN)\n",
    "print(NN_into_IN)\n",
    "print(DT_into_VB)\n",
    "print(VB_into_IN)\n",
    "print(DT_into_VBP)\n",
    "print(VBP_into_IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_promise_probility = 0\n",
    "VB_promise_probility = 0\n",
    "VBP_promise_probility = 0\n",
    "\n",
    "NN_promise_probility = (DT_into_NN/total_DT)*(NN_into_IN/total_NN)*(promise_list[0][1]/total_NN)   # promise_list[0][1] > promise가 NN이라고 태깅된 개수\n",
    "VB_promise_probility = (DT_into_VB/total_DT)*(VB_into_IN/total_VB)*(promise_list[1][1]/total_VB)   # promise_list[1][1] > promise가 VB이라고 태깅된 개수\n",
    "VBP_promise_probility = (DT_into_VBP/total_DT)*(VBP_into_IN/total_VBP)*(promise_list[2][1]/total_VBP)  # promise_list[2][1] > promise가 VBP이라고 태깅된 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1812692272326626e-05\n",
      "2.0539528057091892e-07\n",
      "5.222829609883643e-08\n"
     ]
    }
   ],
   "source": [
    "print(NN_promise_probility)\n",
    "print(VB_promise_probility)\n",
    "print(VBP_promise_probility)\n",
    "\n",
    "# every 다음 promise 다음 of일 경우 promise는 NN일 확률이 더 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
