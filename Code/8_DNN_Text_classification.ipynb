{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt=Okt()\n",
    "\n",
    "file = open('./ratings_test.txt', 'r', encoding='utf-8-sig')\n",
    "\n",
    "sentences = []\n",
    "label = []\n",
    "\n",
    "\n",
    "for idx, line in enumerate(file):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    line = line.split('\\t')\n",
    "    sentences.append(line[1])\n",
    "    label.append(line[2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_pos = []\n",
    "\n",
    "for line in sentences:\n",
    "    sentences_pos.append(okt.morphs(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['굳', 'ㅋ'], ['GDNTOPCLASSINTHECLUB'], ['뭐', '야', '이', '평점', '들', '은', '....', '나쁘진', '않지만', '10', '점', '짜', '리', '는', '더', '더욱', '아니잖아'], ['지루하지는', '않은데', '완전', '막장', '임', '...', '돈', '주고', '보기', '에는', '....'], ['3', 'D', '만', '아니었어도', '별', '다섯', '개', '줬을텐데', '..', '왜', '3', 'D', '로', '나와서', '제', '심기', '를', '불편하게', '하죠', '??']]\n"
     ]
    }
   ],
   "source": [
    "print(sentences_pos[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(i) for i in sentences_pos])\n",
    "\n",
    "vocab = set()\n",
    "for line in sentences_pos:\n",
    "    for word in line:\n",
    "        vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)+1\n",
    "\n",
    "vocab = sorted(list(vocab))\n",
    "\n",
    "vocab_index = {}\n",
    "for i in range(len(vocab)):\n",
    "    vocab_index[vocab[i]] = len(vocab_index)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나서써라', '나서야', '나서의', '나선', '나설', '나섰다가', '나성', '나셨어', '나소', '나수윤']\n",
      "9991\n"
     ]
    }
   ],
   "source": [
    "print(vocab[9990:10000])\n",
    "print(vocab_index['나서써라'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sentences = []\n",
    "\n",
    "for line in sentences_pos:\n",
    "    etc = []\n",
    "    for word in line:\n",
    "        etc.append(vocab_index[word])\n",
    "    int_sentences.append(etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7000, 3312], [1790], [21891, 34951, 40013, 52555, 16227, 39776, 406, 9955, 34363, 626, 44517, 47854, 18306, 12735, 14272, 14369, 33161], [47084, 34326, 38030, 18752, 41581, 378, 14894, 45887, 24632, 36379, 406], [1010, 1718, 18782, 33122, 24384, 13187, 4948, 46673, 346, 38146, 1010, 1718, 18049, 10265, 44855, 31885, 18300, 26512, 53798, 1567]]\n"
     ]
    }
   ],
   "source": [
    "print(int_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padding_sentences = []\n",
    "\n",
    "int_sentences = pad_sequences(int_sentences, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['음악', '이', '주가', '된', ',', '최고', '의', '음악', '영화']\n",
      "[39881 40013 45872 15654   203 49613 39934 39881 37170     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(sentences_pos[5])\n",
    "print(int_sentences[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "label_one_hot = to_categorical(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(label_one_hot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_etc, y_train, y_etc = train_test_split(int_sentences, label_one_hot, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_etc, y_etc, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 82)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 82, 64)            3635968   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5248)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                335936    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,976,194\n",
      "Trainable params: 3,976,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Input, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "embedding_size = 64\n",
    "\n",
    "input_data = Input(shape=(max_len, ))\n",
    "\n",
    "emd = Embedding(vocab_size, 64)(input_data)\n",
    "\n",
    "flatten = Flatten()(emd)\n",
    "\n",
    "dense1 = Dense(64, activation='relu')(flatten)\n",
    "dense2 = Dense(64, activation='relu')(dense1)\n",
    "dense3 = Dense(2, activation='softmax')(dense2)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=dense3)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "30000/30000 [==============================] - 13s 435us/step - loss: 0.5712 - acc: 0.6818 - val_loss: 0.4085 - val_acc: 0.8138\n",
      "Epoch 2/8\n",
      "30000/30000 [==============================] - 12s 404us/step - loss: 0.2686 - acc: 0.8911 - val_loss: 0.4314 - val_acc: 0.8078\n",
      "Epoch 00002: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b8c81c9828>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss',mode='min',verbose=1)\n",
    "\n",
    "model.fit([X_train], y_train, batch_size=256, epochs=8, validation_data=([X_val], y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 39us/step\n",
      "Loss: 0.43668007271289827\n",
      "Accuracy: 0.8083\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate([X_test], y_test)\n",
    "\n",
    "print('Loss: '+str(evaluation[0]))\n",
    "print('Accuracy: '+str(evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
