{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4.element import Tag\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"./reuters.xml\", \"r\", \"utf-8\") as infile:\n",
    "    soup = bs(infile, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Paxar', 'N'), ('Corp', 'N'), ('said', 'I'), ('it', 'I'), ('has', 'I')]\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for elem in soup.find_all('document'):\n",
    "    texts = []\n",
    "    \n",
    "    # \"textwithnamedentities\" 라는 이름의 태그 요소 안에 있는 내용을 반복문을 통해 가져오기\n",
    "    for c in elem.find('textwithnamedentities').children:\n",
    "        \n",
    "        if type(c) == Tag:\n",
    "            if c.name == 'namedentityintext':\n",
    "                label = 'N'   # Named Entity 부분이라는 의미\n",
    "            else:\n",
    "                label = 'I'   # 상관없는 단어들은 'I'로 표시\n",
    "            \n",
    "            for w in c.text.split(' '):\n",
    "                if len(w) > 0:\n",
    "                    texts.append((w, label))\n",
    "    docs.append(texts)\n",
    "    \n",
    "print(docs[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HTS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# 품사 태그(Part-of-Speech Tags) 생성\n",
    "import nltk\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    # 문서에서 토큰(단어)을 가져와 리스트에 저장\n",
    "    tokens = [t for t, label in doc]\n",
    "    \n",
    "    # 품사 태그 확인\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # 단어, 품사 태그, 그리고 label을 저장\n",
    "    data.append([(w, pos, label) for (w, label), (word, pos) in zip(doc, tagged)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Paxar', 'NNP', 'N'), ('Corp', 'NNP', 'N'), ('said', 'VBD', 'I'), ('it', 'PRP', 'I'), ('has', 'VBZ', 'I')]\n"
     ]
    }
   ],
   "source": [
    "print(data[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Feature 생성\n",
    "def word2features(doc, i):\n",
    "    word = doc[i][0]\n",
    "    pos_tag = doc[i][1]\n",
    "    \n",
    "    #모든 단어에서의 공통적인 특징\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + pos_tag\n",
    "    ]\n",
    "    \n",
    "    # 문서의 시작 부분\n",
    "    if i > 0:\n",
    "        word1 = doc[i-1][0]\n",
    "        pos_tag1 = doc[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '-1:pos_tag=' + pos_tag1\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        # 있다면 \"문서의 시작\"이라고 표시\n",
    "        features.append('BOS')\n",
    "    \n",
    "    #문서의 마지막 부분\n",
    "    if i < len(doc)-1:\n",
    "        word1 = doc[i+1][0]\n",
    "        pos_tag1 = doc[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '+1:pos_tag=' + pos_tag1\n",
    "        ])\n",
    "        \n",
    "    else:\n",
    "        # 있다면 \"문서의 마지막\"이라고 표시\n",
    "        features.append('EOS')\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 모델에 학습 진행\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 문서에서 feature(특징)을 추출하는 함수 선언\n",
    "def extract_features(doc):\n",
    "    return [word2features(doc, i) for i in range(len(doc))]\n",
    "\n",
    "# 각 문서의 label에 대한 정보를 저장하는 리스트를 생성하는 함수 선언\n",
    "def get_labels(doc):\n",
    "    return [label for (token, postag, label) in doc]\n",
    "\n",
    "X = [extract_features(doc) for doc in data]\n",
    "y = [get_labels(doc) for doc in data]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CRF 모델 사용\n",
    "import pycrfsuite\n",
    "\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "# 모델에 학습 데이터를 입력\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "    \n",
    "# 모델의 파라미터 설정\n",
    "trainer.set_params({\n",
    "    # L1 penalty의 계수\n",
    "    'c1' : 0.1,\n",
    "    \n",
    "    # L2 penalty의 계수\n",
    "    'c2' : 0.01,\n",
    "    \n",
    "    # 최대 반복 횟수\n",
    "    'max_iterations' : 200,\n",
    "    \n",
    "    'feature.possible_transitions' : True\n",
    "})\n",
    "\n",
    "# 모델 학습, 학습이 끝난 후, \"crf.model\"의 이름으로 모델을 파일로 저장\n",
    "trainer.train('crf.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investment (N)\n",
      "technologies (N)\n",
      "inc (N)\n",
      "said (I)\n",
      "it (I)\n",
      "will (I)\n",
      "make (I)\n",
      "available (I)\n",
      "its (I)\n",
      "online (I)\n",
      "investment (I)\n",
      "advisory (I)\n",
      "service (I)\n",
      "to (I)\n",
      "spear (N)\n",
      "securities (N)\n",
      "inc (N)\n",
      "customers. (I)\n",
      "investment (N)\n",
      "technologies (N)\n",
      "said (I)\n",
      "that (I)\n",
      "through (I)\n",
      "a (I)\n",
      "spear (I)\n",
      "rebate (I)\n",
      "program, (I)\n",
      "purchasers (I)\n",
      "of (I)\n",
      "the (I)\n",
      "investment (I)\n",
      "advisory (I)\n",
      "service, (I)\n",
      "vestor, (I)\n",
      "can (I)\n",
      "receive (I)\n",
      "a (I)\n",
      "cash (I)\n",
      "rebate (I)\n",
      "of (I)\n",
      "up (I)\n",
      "to (I)\n",
      "the (I)\n",
      "full (I)\n",
      "subscription (I)\n",
      "price (I)\n",
      "of (I)\n",
      "the (I)\n",
      "investment (I)\n",
      "advisory (I)\n",
      "service (I)\n",
      "from (I)\n",
      "spear (N)\n",
      "securities (N)\n",
      ". (I)\n",
      "spears (I)\n",
      "brokerage (I)\n",
      "commission (I)\n",
      "rebate (I)\n",
      "program (I)\n",
      "will (I)\n",
      "allow (I)\n",
      "money (I)\n",
      "managers (I)\n",
      "or (I)\n",
      "individual (I)\n",
      "investors (I)\n",
      "who (I)\n",
      "purchase (I)\n",
      "vestor (I)\n",
      "from (I)\n",
      "investment (N)\n",
      "technologies (N)\n",
      ", (I)\n",
      "or (I)\n",
      "from (I)\n",
      "other (I)\n",
      "authorized (I)\n",
      "distributors, (I)\n",
      "to (I)\n",
      "recive (I)\n",
      "a (I)\n",
      "rebate (I)\n",
      "of (I)\n",
      "the (I)\n",
      "brokerage (I)\n",
      "commissions, (I)\n",
      "the (I)\n",
      "company (I)\n",
      "said. (I)\n",
      "each (I)\n",
      "month (I)\n",
      "spear (N)\n",
      "will (I)\n",
      "send (I)\n",
      "participating (I)\n",
      "customers (I)\n",
      "a (I)\n",
      "check (I)\n",
      "equal (I)\n",
      "up (I)\n",
      "to (I)\n",
      "25 (I)\n",
      "pct (I)\n",
      "of (I)\n",
      "monthly (I)\n",
      "commissions (I)\n",
      "generated (I)\n",
      "by (I)\n",
      "the (I)\n",
      "client (I)\n",
      "account, (I)\n",
      "it (I)\n",
      "added. (I)\n"
     ]
    }
   ],
   "source": [
    "#### 결과 확인\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('crf.model')\n",
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "\n",
    "# 테스트 세트에서 임의의 샘플을 출력\n",
    "i = 8\n",
    "for x, y in zip(y_pred[i], [x[1].split(\"=\")[1] for x in X_test[i]]):\n",
    "    print(\"%s (%s)\" % (y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           I       0.98      0.99      0.98      2579\n",
      "           N       0.92      0.84      0.88       386\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2965\n",
      "   macro avg       0.95      0.92      0.93      2965\n",
      "weighted avg       0.97      0.97      0.97      2965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Sklearn으로 보기 쉽게 성능을 확인\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# label을 탐색하기 위한 딕셔너리 생성\n",
    "labels = {\"N\" : 1, \"I\" : 0}\n",
    "\n",
    "# 문자열의 태그를 1차원의 배열로 변환\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "# 분류 성능 결과 출력\n",
    "print(classification_report(truths, predictions, target_names=[\"I\", \"N\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
